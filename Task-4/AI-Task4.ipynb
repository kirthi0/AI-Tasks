{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7a45a62",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "Random Forest Classifier : Perform Classification on IRIS DATASET and MNIST DATASET using Random Forest Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e74bb1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset: (149, 5) \n",
      "\n",
      "Dataset:\n",
      "    5.1  3.5  1.4  0.2  Iris-setosa\n",
      "0  4.9  3.0  1.4  0.2  Iris-setosa\n",
      "1  4.7  3.2  1.3  0.2  Iris-setosa\n",
      "2  4.6  3.1  1.5  0.2  Iris-setosa\n",
      "3  5.0  3.6  1.4  0.2  Iris-setosa\n",
      "4  5.4  3.9  1.7  0.4  Iris-setosa\n",
      "Test dataset: [[7.2 3.  5.8 1.6]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [6.  2.2 5.  1.5]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [5.9 3.  5.1 1.8]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [4.4 3.  1.3 0.2]]\n",
      "Predicted classes: [2 0 1 0 2 2 0 0 2 0 0 2 0 0 2 1 1 1 2 2 2 0 2 0 2 2 1 0 1 2 1 2 2 0 0 1 0\n",
      " 1 2 2 0 1 2 2 0]\n",
      "Accuracy: 95.55555555555556\n",
      "Confusion matrix:\n",
      " [[16  0  0]\n",
      " [ 0  9  1]\n",
      " [ 0  1 18]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       0.90      0.90      0.90        10\n",
      "           2       0.95      0.95      0.95        19\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.95      0.95      0.95        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "import numpy as np\n",
    "\n",
    "df_iris = pd.read_csv('iris.data')\n",
    "\n",
    "print(\"Shape of the dataset:\",df_iris.shape,\"\\n\")\n",
    "print(\"Dataset:\\n\",df_iris.head())\n",
    "\n",
    "X = df_iris.iloc[:,:-1].values\n",
    "y = df_iris.iloc[:,-1].values\n",
    "\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "#splitting the dataset for training  and validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3,random_state = 100)\n",
    "\n",
    "clf = RandomForestClassifier(random_state = 100)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Test dataset:\",X_test)\n",
    "print(\"Predicted classes:\",y_pred)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test,y_pred)*100)\n",
    "\n",
    "print(\"Confusion matrix:\\n\",confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"Classification report:\\n\",classification_report(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b270b57c",
   "metadata": {},
   "source": [
    "### LOGISTIC REGRESSION - QUESTION 2\n",
    "Heart Disease Prediction using Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "70bfb97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset: (4238, 16) \n",
      "\n",
      "male                 0\n",
      "age                  0\n",
      "education          105\n",
      "currentSmoker        0\n",
      "cigsPerDay          29\n",
      "BPMeds              53\n",
      "prevalentStroke      0\n",
      "prevalentHyp         0\n",
      "diabetes             0\n",
      "totChol             50\n",
      "sysBP                0\n",
      "diaBP                0\n",
      "BMI                 19\n",
      "heartRate            1\n",
      "glucose            388\n",
      "TenYearCHD           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn import linear_model\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "df_framingham = pd.read_csv(\"framingham.csv\")\n",
    "\n",
    "print(\"Shape of the dataset:\",df_framingham.shape,\"\\n\")\n",
    "\n",
    "print(df_framingham.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6369deb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male               0\n",
      "age                0\n",
      "education          0\n",
      "currentSmoker      0\n",
      "cigsPerDay         0\n",
      "BPMeds             0\n",
      "prevalentStroke    0\n",
      "prevalentHyp       0\n",
      "diabetes           0\n",
      "totChol            0\n",
      "sysBP              0\n",
      "diaBP              0\n",
      "BMI                0\n",
      "heartRate          0\n",
      "glucose            0\n",
      "TenYearCHD         0\n",
      "dtype: int64\n",
      "(3656, 16)\n"
     ]
    }
   ],
   "source": [
    "df_framingham.dropna(inplace = True)\n",
    "print(df_framingham.isnull().sum())\n",
    "print(df_framingham.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eafd34e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.22971741112124\n",
      "Confusion matrix:\n",
      " [[919   3]\n",
      " [170   5]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       922\n",
      "           1       0.62      0.03      0.05       175\n",
      "\n",
      "    accuracy                           0.84      1097\n",
      "   macro avg       0.73      0.51      0.48      1097\n",
      "weighted avg       0.81      0.84      0.78      1097\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_dff = df_framingham.iloc[:,:-1].values\n",
    "y_dff = df_framingham.iloc[:,-1].values\n",
    "\n",
    "#splitting the dataset for training  and validation\n",
    "X_dff_train, X_dff_test, y_dff_train, y_dff_test = train_test_split(X_dff,y_dff,test_size = 0.3,random_state = 100)\n",
    "\n",
    "clf = linear_model.LogisticRegression()\n",
    "\n",
    "clf.fit(X_dff_train, y_dff_train)\n",
    "y_dff_pred = clf.predict(X_dff_test)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_dff_test,y_dff_pred)*100)\n",
    "\n",
    "print(\"Confusion matrix:\\n\",confusion_matrix(y_dff_test,y_dff_pred))\n",
    "\n",
    "print(\"Classification report:\\n\",classification_report(y_dff_test,y_dff_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631501c6",
   "metadata": {},
   "source": [
    "Question 3\n",
    "### Support Vector Machine (SVM) : Perform iris data classification using SVM ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "20590630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b8aff67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset: [[0 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " ...\n",
      " [1 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]]\n",
      "Predicted classes: [0 0 1 ... 0 0 0]\n",
      "Accuracy: 96.77005895924123\n",
      "Confusion matrix:\n",
      " [[3342   31]\n",
      " [  95  433]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      3373\n",
      "           1       0.93      0.82      0.87       528\n",
      "\n",
      "    accuracy                           0.97      3901\n",
      "   macro avg       0.95      0.91      0.93      3901\n",
      "weighted avg       0.97      0.97      0.97      3901\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#splitting the dataset for training  and validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.7,random_state = 100)\n",
    "\n",
    "svclf = SVC(kernel = 'linear',random_state = 0)\n",
    "\n",
    "svclf.fit(X_train, y_train)\n",
    "y_Pred = svclf.predict(X_test)\n",
    "\n",
    "print(\"Test dataset:\",X_test)\n",
    "print(\"Predicted classes:\",y_Pred)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test,y_Pred)*100)\n",
    "\n",
    "print(\"Confusion matrix:\\n\",confusion_matrix(y_test, y_Pred))\n",
    "\n",
    "print(\"Classification report:\\n\",classification_report(y_test,y_Pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ffd2a8",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "Naive Bayes : Perform spam email detection using Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "372ebec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4bd45fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 2)\n",
      "First 5 lines of the dataset:\n",
      "   Category                                            Message\n",
      "0      ham  Go until jurong point, crazy.. Available only ...\n",
      "1      ham                      Ok lar... Joking wif u oni...\n",
      "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3      ham  U dun say so early hor... U c already then say...\n",
      "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
      "Test data:\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 3 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]] \n",
      "predicted_categories:\n",
      "[0 0 1 ... 0 0 0] \n",
      "actual_categories:\n",
      "[0 0 0 ... 0 0 0]\n",
      "Accuracy: 97.48803827751196\n",
      "Confusion matrix:\n",
      " [[1418   22]\n",
      " [  20  212]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      1440\n",
      "           1       0.91      0.91      0.91       232\n",
      "\n",
      "    accuracy                           0.97      1672\n",
      "   macro avg       0.95      0.95      0.95      1672\n",
      "weighted avg       0.97      0.97      0.97      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label = []\n",
    "features = [] \n",
    "words = []\n",
    "\n",
    "df_email = pd.read_csv('spam.csv')\n",
    "print(df_email.shape)\n",
    "print(\"First 5 lines of the dataset:\\n\",df_email.head())\n",
    "\n",
    "for i in range(df_email.shape[0]):\n",
    "    blob=str(df_email.iloc[i,1])\n",
    "    \n",
    "    words+=blob.split(\" \")\n",
    "    \n",
    "for i in range(len(words)):\n",
    "    if not words[i].isalpha():\n",
    "        words[i]=\"\"\n",
    "\n",
    "\n",
    "word_dict = Counter(words)\n",
    "del word_dict[\"\"]\n",
    "word_dict = word_dict.most_common(3000)\n",
    "\n",
    "for i in range(df_email.shape[0]):\n",
    "    blob=df_email.iloc[i,1].split()\n",
    "    data = []\n",
    "\n",
    "    for i in word_dict:\n",
    "        data.append(blob.count(i[0]))\n",
    "        \n",
    "    features.append(data) \n",
    "    \n",
    "X = np.array(features)    \n",
    "y = df_email.iloc[:,0].values\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "\n",
    "X_train, X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n",
    "\n",
    "\n",
    "clf=MultinomialNB()\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "print(f'Test data:\\n{X_test} \\npredicted_categories:\\n{y_pred} \\nactual_categories:\\n{y_test}')\n",
    "print(\"Accuracy:\",accuracy_score(y_test,y_pred)*100)\n",
    "\n",
    "print(\"Confusion matrix:\\n\",confusion_matrix(y_test,y_pred))\n",
    "\n",
    "print(\"Classification report:\\n\",classification_report(y_test,y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22949926",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
